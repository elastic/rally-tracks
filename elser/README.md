## ELSER Track

This track benchmarks compound weighted terms queries and BM25 match queries using OOTB settings,
both sets of queries are run with the Block Max WAND optimisation disabled and enabled.
Max WAND optimisation is controlled by the `track_total_hits` query parameter (set to `false` 
to _enable_ Block Max WAND and `true` to _disable_).

The `text_expansion` query rewrites to a compound weighted term query using the token weights
retuned by evaluating the [ELSER](https://www.elastic.co/guide/en/machine-learning/master/ml-nlp-elser.html) model. For benchmarking, evaluating the NLP model is not necessary nor is it desired as the 
purpose is to test the generated query. The query terms are pre-generated by the ELSER model
and hard coded into the searches. 


The BM25 match queries are present to establish a benchmark for comparrison with the
weighted term queries. 


### Generating the queries
The weighted tokens are found by evaluating ELSER with the [Inference API](https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-trained-model.html) passing the query text.
The response of the inference call contains the weighted tokens which are converted to
the query with the following `jq` command:

```

 jq '.inference_results | .[0] | .predicted_value | { "query": {"bool": { "should":  [ to_entries | .[] | {term: { "ml.tokens": { value: .key, boost: .value } } } ] } } } ' infer_output.json

```
In this example the file `infer_output.json` contains the response of the inference call.


The benchmark considers queries with different numbers of terms. Again these queries are created from the inference 
response, the following script creates the operations in `operations/weighted-token-queries.json`. The first argument to the script 
is a file containing the inference response. 

```
#!/bin/sh

if [ -z $1 ]
then 
	echo "Missing input file: usgae ./gen_queries.sh input_json"; 
	exit 1
fi

INPUT_FILE=$1

for NUM_TOKENS in 10 20 30 40 50
do

	TRACK_TOTAL_HITS=true
	QUERY_NAME=$NUM_TOKENS-weighted-terms-maxwand-disabled

	jq --arg track_total $TRACK_TOTAL_HITS --argjson num_tokens $NUM_TOKENS --arg name $QUERY_NAME '.inference_results | .[0] | .predicted_value | { "name": $name,  "operation-type": "search", "body": { "track_total_hits": $track_total, "query": {"bool": { "should":  [ to_entries | .[0:$num_tokens] | .[] | {term: { "ml.tokens": { value: .key, boost: .value } } } ] } } } }' $INPUT_FILE

	echo ','

	TRACK_TOTAL_HITS=false
	QUERY_NAME=$NUM_TOKENS-weighted-terms-maxwand-enabled

	jq --arg track_total $TRACK_TOTAL_HITS --argjson num_tokens $NUM_TOKENS --arg name $QUERY_NAME '.inference_results | .[0] | .predicted_value | { "name": $name,  "operation-type": "search", "body": { "track_total_hits": $track_total, "query": {"bool": { "should":  [ to_entries | .[0:$num_tokens] | .[] | {term: { "ml.tokens": { value: .key, boost: .value } } } ] } } } }' $INPUT_FILE

	echo ','
done 

```

### Preparing the Dataset
<!-- TODO Ingest MS Marco details. -->


Once restored the MS Marco passage documents need to be run through ELSER to generate the tokens.
This is done by reindexing through an ingest pipeline containing the inference processor.


Firt, put the pipeline
```  
PUT _ingest/pipeline/elser
{
  "processors": [
    {
      "inference": {
        "model_id": ".elser_model_1",
        "field_map": {
          "body": "text_field"
        },
        "target_field": "ml",
        "inference_config": {
          "text_expansion": {
            "results_field": "tokens"
          }
        }
      }
    }
  ]
}
```

Then reindex. `max_docs` is used to limit the number of documents
```
POST _reindex?wait_for_completion=false
{
  "max_docs": 100000,
  "source": {
    "index": "msmarco-passage-collection",
    "size": 50
  },
  "dest": {
    "index": "msmarco-passage-collection-elser",
    "pipeline": "elser"
  }
}
```


### Parameters
This track accepts the following parameters with Rally 0.8.0+ using `--track-params`:

* `bulk_size` (default: 5000)
* `bulk_indexing_clients` (default: 8)
* `ingest_percentage` (default: 100)

### License
?
T&Cs at https://microsoft.github.io/msmarco/


### Citation
@article{bajaj2016ms,
title={Ms marco: A human generated machine reading comprehension dataset},
author={Bajaj, Payal and Campos, Daniel and Craswell, Nick and Deng, Li and Gao, Jianfeng and Liu, Xiaodong and Majumder, Rangan and McNamara, Andrew and Mitra, Bhaskar and Nguyen, Tri and others},
journal={arXiv preprint arXiv:1611.09268},
year={2016}
}

