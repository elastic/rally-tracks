## MS MARCO Passage ELSER Track

This track benchmarks compound weighted terms queries and BM25 match queries using OOTB settings, both sets of queries are run with the Block Max WAND optimization disabled and enabled. Max WAND optimization is controlled by the `track_total_hits` query parameter (set to `false` to _enable_ Block Max WAND and `true` to _disable_).

The `text_expansion` query rewrites to a compound weighted term query using the token weights returned by evaluating the [ELSER](https://www.elastic.co/guide/en/machine-learning/master/ml-nlp-elser.html) model. For benchmarking, evaluating the NLP model is not necessary nor is it desired as the purpose is to test the generated query. The query terms are pre-generated by the ELSER model and hard coded into the searches. 


The BM25 match queries are present to establish a benchmark for comparison with the weighted term queries. 


### Generating the queries
The weighted tokens are found by evaluating ELSER with the [Inference API](https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-trained-model.html) passing the query text. The response of the inference call contains the weighted tokens which are converted to the query with the following `jq` command:

```

 jq '.inference_results | .[0] | .predicted_value | { "query": {"bool": { "should":  [ to_entries | .[] | {term: { "ml.tokens": { value: .key, boost: .value } } } ] } } } ' infer_output.json

```
In this example the file `infer_output.json` contains the response of the inference call.


The benchmark considers queries with different numbers of terms. Again these queries are created from the inference API response, the following script creates the operations in `operations/weighted-token-queries.json`. The first argument to the script is a file containing the inference response. 

```
#!/bin/sh

if [ -z $1 ]
then 
	echo "Missing input file: usage ./gen_queries.sh input_json"; 
	exit 1
fi

INPUT_FILE=$1

for NUM_TOKENS in 10 20 30 40 50
do

	TRACK_TOTAL_HITS=true
	QUERY_NAME=$NUM_TOKENS-weighted-terms-maxwand-disabled

	jq --arg track_total $TRACK_TOTAL_HITS --argjson num_tokens $NUM_TOKENS --arg name $QUERY_NAME '.inference_results | .[0] | .predicted_value | { "name": $name,  "operation-type": "search", "body": { "track_total_hits": $track_total, "query": {"bool": { "should":  [ to_entries | .[0:$num_tokens] | .[] | {term: { "ml.tokens": { value: .key, boost: .value } } } ] } } } }' $INPUT_FILE

	echo ','

	TRACK_TOTAL_HITS=false
	QUERY_NAME=$NUM_TOKENS-weighted-terms-maxwand-enabled

	jq --arg track_total $TRACK_TOTAL_HITS --argjson num_tokens $NUM_TOKENS --arg name $QUERY_NAME '.inference_results | .[0] | .predicted_value | { "name": $name,  "operation-type": "search", "body": { "track_total_hits": $track_total, "query": {"bool": { "should":  [ to_entries | .[0:$num_tokens] | .[] | {term: { "ml.tokens": { value: .key, boost: .value } } } ] } } } }' $INPUT_FILE

	echo ','
done 

```

### Preparing the Dataset
https://microsoft.github.io/msmarco/Datasets.html has download links to all the the MS MARCO datasets.
Ingest the [Passage ranking dataset](https://microsoft.github.io/msmarco/Datasets.html#passage-ranking-dataset) into the Elasticsearch index `msmarco-passage-collection`. Once ingested the MS Marco passage documents need to be run through ELSER to generate the tokens. This is achieved by reindexing through an ingest pipeline containing the inference processor.


First, put the ingest pipeline
```  
PUT _ingest/pipeline/elser
{
  "processors": [
    {
      "inference": {
        "model_id": ".elser_model_1",
        "field_map": {
          "body": "text_field"
        },
        "target_field": "ml",
        "inference_config": {
          "text_expansion": {
            "results_field": "tokens"
          }
        }
      }
    }
  ]
}
```

Create the destination index with the correct rank_features mapping
```
PUT msmarco-passage-collection-elser
{
  "mappings": {
    "properties": {
      "body": {
        "type": "text"
      },
      "id": {
        "type": "keyword",
        "ignore_above": 1024
      },
      "ml": {
        "properties": {
          "model_id": {
            "type": "text",
            "fields": {
              "keyword": {
                "type": "keyword",
                "ignore_above": 256
              }
            }
          },
          "tokens": {
            "type": "rank_features"
          }
        }
      }
    }
  }
}
```

Then reindex the passages through the `elser` pipeline. 
`max_docs` is used to limit the number of documents

```
POST _reindex?wait_for_completion=false
{
  "max_docs": 100000,
  "source": {
    "index": "msmarco-passage-collection",
    "size": 50
  },
  "dest": {
    "index": "msmarco-passage-collection-elser",
    "pipeline": "elser"
  }
}
```

The `msmarco-passage-collection-elser` index now contains the original documents with a new rank features field `ml.tokens` containing the token weights. These are the documents used in this benchmark.


### Parameters
This track accepts the following parameters with Rally 0.8.0+ using `--track-params`:

* `bulk_size` (default: 5000)
* `bulk_indexing_clients` (default: 8)
* `ingest_percentage` (default: 100)

### License
?
T&Cs at https://microsoft.github.io/msmarco/


### Citation
@article{bajaj2016ms,
title={Ms marco: A human generated machine reading comprehension dataset},
author={Bajaj, Payal and Campos, Daniel and Craswell, Nick and Deng, Li and Gao, Jianfeng and Liu, Xiaodong and Majumder, Rangan and McNamara, Andrew and Mitra, Bhaskar and Nguyen, Tri and others},
journal={arXiv preprint arXiv:1611.09268},
year={2016}
}

