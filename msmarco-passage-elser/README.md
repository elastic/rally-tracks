## MS MARCO Passage ELSER Track

This track benchmarks compound weighted terms queries and BM25 match queries using OOTB settings, both sets of queries are run with the Block Max WAND optimization disabled and enabled. Block Max WAND optimization is controlled by the `track_total_hits` query parameter (set to `false` to _enable_ Block Max WAND and `true` to _disable_).

The `text_expansion` query rewrites to a compound weighted term query using the token weights returned by evaluating the [ELSER](https://www.elastic.co/guide/en/machine-learning/master/ml-nlp-elser.html) model. For benchmarking, evaluating the NLP model is not necessary nor is it desired as the purpose is to test the weighted terms query. The query terms are pre-generated by the ELSER model and hard coded into the searches. 

The BM25 match queries are present to establish a benchmark for comparison with the weighted term queries. 

### Generating the Query Tokens
The weighted tokens are found by evaluating ELSER with the [Inference API](https://www.elastic.co/guide/en/elasticsearch/reference/current/infer-trained-model.html) passing the query text. The tokens in the response of the inference call are saved to the file `elser-query-tokens.json` which is then consumed by the `weighted-terms-param-source` parameter source. `weighted-terms-param-source` emits the compound weighted terms queries unsed in the benchmark.

`weighted-terms-param-source` has the following option parameters:

* `index`, (default default_index)
* `cache`: (default False)
* `size`: The search size (default 10)
* `field`: (default "ml.tokens")
* `tokens-source`: The file containing the query terms (default "elser-query-tokens.json")
* `num-terms`: Controls the number of terms in the query (default 10)
* `track_total_hits`: (default False)

### Preparing the Dataset
https://microsoft.github.io/msmarco/Datasets.html has download links to all the the MS MARCO datasets.
Ingest the [Passage ranking dataset](https://microsoft.github.io/msmarco/Datasets.html#passage-ranking-dataset) into the Elasticsearch index `msmarco-passage-collection`. Once ingested the MS Marco passage documents need to be run through ELSER to generate the tokens. This is achieved by reindexing through an ingest pipeline containing the inference processor.

First, put the ingest pipeline
```  
PUT _ingest/pipeline/elser
{
  "processors": [
    {
      "inference": {
        "model_id": ".elser_model_1",
        "field_map": {
          "body": "text_field"
        },
        "target_field": "ml",
        "inference_config": {
          "text_expansion": {
            "results_field": "tokens"
          }
        }
      }
    }
  ]
}
```

Create the destination index with the rank_features mapping for the `ml.tokens` field.
```
PUT msmarco-passage-collection-elser
{
  "mappings": {
    "properties": {
      "body": {
        "type": "text"
      },
      "id": {
        "type": "keyword",
        "ignore_above": 1024
      },
      "ml": {
        "properties": {
          "model_id": {
            "type": "text",
            "fields": {
              "keyword": {
                "type": "keyword",
                "ignore_above": 256
              }
            }
          },
          "tokens": {
            "type": "rank_features"
          }
        }
      }
    }
  }
}
```

Then reindex the passages through the `elser` pipeline. 
`max_docs` is used to limit the number of documents

```
POST _reindex?wait_for_completion=false
{
  "max_docs": 1000000,
  "source": {
    "index": "msmarco-passage-collection",
    "size": 50
  },
  "dest": {
    "index": "msmarco-passage-collection-elser",
    "pipeline": "elser"
  }
}
```

Once complete the `msmarco-passage-collection-elser` index contains the original documents with a new rank features field `ml.tokens` containing the token weights. These are the documents used in this benchmark.

### Parameters
This track accepts the following parameters with Rally 0.8.0+ using `--track-params`:

* `bulk_size` (default: 5000)
* `bulk_indexing_clients` (default: 8)
* `ingest_percentage` (default: 100)

### License
Terms and Conditions for using the MS MARCO datasets can be found at https://microsoft.github.io/msmarco/

### Citation
@article{bajaj2016ms,
title={Ms marco: A human generated machine reading comprehension dataset},
author={Bajaj, Payal and Campos, Daniel and Craswell, Nick and Deng, Li and Gao, Jianfeng and Liu, Xiaodong and Majumder, Rangan and McNamara, Andrew and Mitra, Bhaskar and Nguyen, Tri and others},
journal={arXiv preprint arXiv:1611.09268},
year={2016}
}

